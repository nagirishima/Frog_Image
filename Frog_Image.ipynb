{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Frog_Image.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMFIFXQhUseADku4PUbZis",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagirishima/Frog_Image/blob/main/Frog_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj9neRlQXPc5"
      },
      "source": [
        "# 生成者ネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLhdhecCUR9Q"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGkbUyCyUsE-",
        "outputId": "b1155179-fc68-4548-951e-3848a7aae9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "#畳み込み層を追加\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "#32*32にアップサンプリング\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "#さらに畳み込み層を追加\n",
        "x= layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x= layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "#32*32，1チャネルの特徴マップを生成\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "\n",
        "#generatorモデルをインスタンス化\n",
        "#形状が(latent_dim,)の入力を形状が(32, 32, 3)の画像にマッピング\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYgdaroQcJkj"
      },
      "source": [
        "# 判別者ネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzJuirVoXO_8",
        "outputId": "cef23892-52eb-4363-f146-5ebe8387d6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "#ドロップアウト層を一つ追加\n",
        "\n",
        "#分類層\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "#discriminatorモデルをインスタンス化\n",
        "#形状が32*32*3の入力で二値分類を実行\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "#オプティマイザで勾配刈り込みを使用し\n",
        "#訓練を安定させるために学習率減衰を使用(dicay)\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRBTWx90gZNr"
      },
      "source": [
        "# 敵対者ネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hqJ6usJgYZZ"
      },
      "source": [
        "#discriminatorの重みを訓練不可能に設定(これはganモデルにのみ適用される)\n",
        "discriminator.trainable = False\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3yX2ucls8w"
      },
      "source": [
        "# GANの訓練の実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztsDwpYFlsO4",
        "outputId": "8edab3a7-7e40-4b0c-93a4-d1aab79d7056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "#カエルの画像（6）を選択\n",
        "x_train = x_train[y_train.flatten() == 6]\n",
        "\n",
        "#データを正則化\n",
        "x_train = x_train.reshape((x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
        "\n",
        "iterations = 10000\n",
        "batch_size =20\n",
        "\n",
        "#生成された画像の保存先を指定\n",
        "save_dir = '/GAN'\n",
        "\n",
        "start = 0\n",
        "for step in range(iterations):\n",
        "  #潜在空間から点をランダムに抽出\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "  #偽物の画像にデコーディング\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "  #本物の画像と組み合わせる\n",
        "  stop = start + batch_size\n",
        "  real_images = x_train[start: stop]\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "  #本物の画像と偽物の画像を区別するラベルを組み立てる\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "\n",
        "  #ラベルにランダムノイズを追加\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "  #discriminatorを訓練\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "  #潜在空間から点をランダムに抽出\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "  start += batch_size\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "\n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "\n",
        "    print('discriminator loss at step %s: %s' % (step, d_loss))\n",
        "    print('adversarial loss at step %s: %s' % (step, a_loss))\n",
        "\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
        "\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discriminator loss at step 0: 0.6930700540542603\n",
            "adversarial loss at step 0: 0.3704492151737213\n",
            "discriminator loss at step 100: 0.6892052292823792\n",
            "adversarial loss at step 100: 0.7605577111244202\n",
            "discriminator loss at step 200: 0.69190514087677\n",
            "adversarial loss at step 200: 0.7439895868301392\n",
            "discriminator loss at step 300: 0.6926822662353516\n",
            "adversarial loss at step 300: 0.7498670816421509\n",
            "discriminator loss at step 400: 0.692965567111969\n",
            "adversarial loss at step 400: 0.7542592883110046\n",
            "discriminator loss at step 500: 0.6919215321540833\n",
            "adversarial loss at step 500: 0.7507613897323608\n",
            "discriminator loss at step 600: 0.6937016248703003\n",
            "adversarial loss at step 600: 0.7488775253295898\n",
            "discriminator loss at step 700: 0.696782112121582\n",
            "adversarial loss at step 700: 0.778291642665863\n",
            "discriminator loss at step 800: 0.6928269267082214\n",
            "adversarial loss at step 800: 0.7476600408554077\n",
            "discriminator loss at step 900: 0.6888861060142517\n",
            "adversarial loss at step 900: 0.7667003870010376\n",
            "discriminator loss at step 1000: 0.6933701634407043\n",
            "adversarial loss at step 1000: 0.7458100318908691\n",
            "discriminator loss at step 1100: 0.6916678547859192\n",
            "adversarial loss at step 1100: 0.7594122886657715\n",
            "discriminator loss at step 1200: 0.6748858690261841\n",
            "adversarial loss at step 1200: 0.7012649774551392\n",
            "discriminator loss at step 1300: 0.6923888921737671\n",
            "adversarial loss at step 1300: 0.7548441886901855\n",
            "discriminator loss at step 1400: 0.694053053855896\n",
            "adversarial loss at step 1400: 0.7520487308502197\n",
            "discriminator loss at step 1500: 0.6997596025466919\n",
            "adversarial loss at step 1500: 0.7384557127952576\n",
            "discriminator loss at step 1600: 0.6922410130500793\n",
            "adversarial loss at step 1600: 0.7513822317123413\n",
            "discriminator loss at step 1700: 0.6919158101081848\n",
            "adversarial loss at step 1700: 0.7442492246627808\n",
            "discriminator loss at step 1800: 0.7074121236801147\n",
            "adversarial loss at step 1800: 0.7285943627357483\n",
            "discriminator loss at step 1900: 0.6915985345840454\n",
            "adversarial loss at step 1900: 0.7504152059555054\n",
            "discriminator loss at step 2000: 0.6915316581726074\n",
            "adversarial loss at step 2000: 0.7496827244758606\n",
            "discriminator loss at step 2100: 0.6925259828567505\n",
            "adversarial loss at step 2100: 0.7226557731628418\n",
            "discriminator loss at step 2200: 0.692306399345398\n",
            "adversarial loss at step 2200: 0.7472733855247498\n",
            "discriminator loss at step 2300: 0.6924512386322021\n",
            "adversarial loss at step 2300: 0.7224541902542114\n",
            "discriminator loss at step 2400: 0.6918986439704895\n",
            "adversarial loss at step 2400: 0.7462911009788513\n",
            "discriminator loss at step 2500: 0.7052522897720337\n",
            "adversarial loss at step 2500: 0.7426753044128418\n",
            "discriminator loss at step 2600: 0.6919651031494141\n",
            "adversarial loss at step 2600: 0.745221734046936\n",
            "discriminator loss at step 2700: 0.6920188665390015\n",
            "adversarial loss at step 2700: 0.7779715657234192\n",
            "discriminator loss at step 2800: 0.6920483708381653\n",
            "adversarial loss at step 2800: 0.7417253851890564\n",
            "discriminator loss at step 2900: 0.6917356848716736\n",
            "adversarial loss at step 2900: 0.7454501986503601\n",
            "discriminator loss at step 3000: 0.6921906471252441\n",
            "adversarial loss at step 3000: 0.7415598630905151\n",
            "discriminator loss at step 3100: 0.6920590400695801\n",
            "adversarial loss at step 3100: 0.7552730441093445\n",
            "discriminator loss at step 3200: 0.692251980304718\n",
            "adversarial loss at step 3200: 0.7630662322044373\n",
            "discriminator loss at step 3300: 0.6922098994255066\n",
            "adversarial loss at step 3300: 0.7439015507698059\n",
            "discriminator loss at step 3400: 0.6919822096824646\n",
            "adversarial loss at step 3400: 0.7468036413192749\n",
            "discriminator loss at step 3500: 0.6932455897331238\n",
            "adversarial loss at step 3500: 0.7125917077064514\n",
            "discriminator loss at step 3600: 0.6916462779045105\n",
            "adversarial loss at step 3600: 0.7465676069259644\n",
            "discriminator loss at step 3700: 0.6921983361244202\n",
            "adversarial loss at step 3700: 0.7476544380187988\n",
            "discriminator loss at step 3800: 0.6920865774154663\n",
            "adversarial loss at step 3800: 0.739171028137207\n",
            "discriminator loss at step 3900: 0.6918746829032898\n",
            "adversarial loss at step 3900: 0.7602691650390625\n",
            "discriminator loss at step 4000: 0.6916542053222656\n",
            "adversarial loss at step 4000: 0.7405170202255249\n",
            "discriminator loss at step 4100: 0.697117805480957\n",
            "adversarial loss at step 4100: 0.7751094102859497\n",
            "discriminator loss at step 4200: 0.6916554570198059\n",
            "adversarial loss at step 4200: 0.7509946823120117\n",
            "discriminator loss at step 4300: 0.6917994022369385\n",
            "adversarial loss at step 4300: 0.7485047578811646\n",
            "discriminator loss at step 4400: 0.6923531293869019\n",
            "adversarial loss at step 4400: 0.7411269545555115\n",
            "discriminator loss at step 4500: 0.6928316950798035\n",
            "adversarial loss at step 4500: 0.7430515885353088\n",
            "discriminator loss at step 4600: 0.6919765472412109\n",
            "adversarial loss at step 4600: 0.748553991317749\n",
            "discriminator loss at step 4700: 0.692167341709137\n",
            "adversarial loss at step 4700: 0.7449841499328613\n",
            "discriminator loss at step 4800: 0.6921881437301636\n",
            "adversarial loss at step 4800: 0.757621705532074\n",
            "discriminator loss at step 4900: 0.691495418548584\n",
            "adversarial loss at step 4900: 0.7501377463340759\n",
            "discriminator loss at step 5000: 0.6916741132736206\n",
            "adversarial loss at step 5000: 0.7390240430831909\n",
            "discriminator loss at step 5100: 0.692022442817688\n",
            "adversarial loss at step 5100: 0.7385379076004028\n",
            "discriminator loss at step 5200: 0.6916102170944214\n",
            "adversarial loss at step 5200: 0.753663182258606\n",
            "discriminator loss at step 5300: 0.6922332048416138\n",
            "adversarial loss at step 5300: 0.7481054663658142\n",
            "discriminator loss at step 5400: 0.691470742225647\n",
            "adversarial loss at step 5400: 0.7567673921585083\n",
            "discriminator loss at step 5500: 0.6918267011642456\n",
            "adversarial loss at step 5500: 0.74513179063797\n",
            "discriminator loss at step 5600: 0.6916197538375854\n",
            "adversarial loss at step 5600: 0.7579585909843445\n",
            "discriminator loss at step 5700: 0.6916927695274353\n",
            "adversarial loss at step 5700: 0.753662109375\n",
            "discriminator loss at step 5800: 0.6913396120071411\n",
            "adversarial loss at step 5800: 0.7525392174720764\n",
            "discriminator loss at step 5900: 0.6915377974510193\n",
            "adversarial loss at step 5900: 0.7494726181030273\n",
            "discriminator loss at step 6000: 0.7053987383842468\n",
            "adversarial loss at step 6000: 0.7403368949890137\n",
            "discriminator loss at step 6100: 0.6920132637023926\n",
            "adversarial loss at step 6100: 0.7545405626296997\n",
            "discriminator loss at step 6200: 0.6919734477996826\n",
            "adversarial loss at step 6200: 0.7458891868591309\n",
            "discriminator loss at step 6300: 0.6918905973434448\n",
            "adversarial loss at step 6300: 0.7540486454963684\n",
            "discriminator loss at step 6400: 0.6918769478797913\n",
            "adversarial loss at step 6400: 0.7458812594413757\n",
            "discriminator loss at step 6500: 0.6920691728591919\n",
            "adversarial loss at step 6500: 0.7389183044433594\n",
            "discriminator loss at step 6600: 0.6921218633651733\n",
            "adversarial loss at step 6600: 0.7666840553283691\n",
            "discriminator loss at step 6700: 0.6920455694198608\n",
            "adversarial loss at step 6700: 0.7505486011505127\n",
            "discriminator loss at step 6800: 0.76073157787323\n",
            "adversarial loss at step 6800: 1.0941946506500244\n",
            "discriminator loss at step 6900: 0.6942518353462219\n",
            "adversarial loss at step 6900: 0.8095566630363464\n",
            "discriminator loss at step 7000: 0.6917307376861572\n",
            "adversarial loss at step 7000: 0.7444047331809998\n",
            "discriminator loss at step 7100: 0.6920942068099976\n",
            "adversarial loss at step 7100: 0.7367684841156006\n",
            "discriminator loss at step 7200: 0.6917685866355896\n",
            "adversarial loss at step 7200: 0.7477948069572449\n",
            "discriminator loss at step 7300: 0.6919792890548706\n",
            "adversarial loss at step 7300: 0.7413169145584106\n",
            "discriminator loss at step 7400: 0.6921043395996094\n",
            "adversarial loss at step 7400: 0.7429212927818298\n",
            "discriminator loss at step 7500: 0.6915133595466614\n",
            "adversarial loss at step 7500: 0.7378246188163757\n",
            "discriminator loss at step 7600: 0.6965619325637817\n",
            "adversarial loss at step 7600: 0.7536816000938416\n",
            "discriminator loss at step 7700: 0.6919456124305725\n",
            "adversarial loss at step 7700: 0.7415388226509094\n",
            "discriminator loss at step 7800: 0.6899182200431824\n",
            "adversarial loss at step 7800: 0.6706812977790833\n",
            "discriminator loss at step 7900: 0.6918495893478394\n",
            "adversarial loss at step 7900: 0.746367871761322\n",
            "discriminator loss at step 8000: 0.6930079460144043\n",
            "adversarial loss at step 8000: 0.7500661015510559\n",
            "discriminator loss at step 8100: 0.692357063293457\n",
            "adversarial loss at step 8100: 0.7454674243927002\n",
            "discriminator loss at step 8200: 0.6919525861740112\n",
            "adversarial loss at step 8200: 0.7507232427597046\n",
            "discriminator loss at step 8300: 0.6920888423919678\n",
            "adversarial loss at step 8300: 0.7403140068054199\n",
            "discriminator loss at step 8400: 0.691990852355957\n",
            "adversarial loss at step 8400: 0.7488911151885986\n",
            "discriminator loss at step 8500: 0.6914671063423157\n",
            "adversarial loss at step 8500: 0.745404064655304\n",
            "discriminator loss at step 8600: 0.6917737722396851\n",
            "adversarial loss at step 8600: 0.7471243739128113\n",
            "discriminator loss at step 8700: 0.6920615434646606\n",
            "adversarial loss at step 8700: 0.7449976205825806\n",
            "discriminator loss at step 8800: 0.6916677951812744\n",
            "adversarial loss at step 8800: 0.747452974319458\n",
            "discriminator loss at step 8900: 0.6916123628616333\n",
            "adversarial loss at step 8900: 0.7493425011634827\n",
            "discriminator loss at step 9000: 0.6920926570892334\n",
            "adversarial loss at step 9000: 0.7663874626159668\n",
            "discriminator loss at step 9100: 0.6919973492622375\n",
            "adversarial loss at step 9100: 0.7489374279975891\n",
            "discriminator loss at step 9200: 0.6920009851455688\n",
            "adversarial loss at step 9200: 0.7458555102348328\n",
            "discriminator loss at step 9300: 0.6919296979904175\n",
            "adversarial loss at step 9300: 0.7387574315071106\n",
            "discriminator loss at step 9400: 0.6934717297554016\n",
            "adversarial loss at step 9400: 0.7136965990066528\n",
            "discriminator loss at step 9500: 0.691606342792511\n",
            "adversarial loss at step 9500: 0.7526383996009827\n",
            "discriminator loss at step 9600: 0.6914879679679871\n",
            "adversarial loss at step 9600: 0.7418715953826904\n",
            "discriminator loss at step 9700: 0.6924132108688354\n",
            "adversarial loss at step 9700: 0.744827389717102\n",
            "discriminator loss at step 9800: 0.6924344301223755\n",
            "adversarial loss at step 9800: 0.7487724423408508\n",
            "discriminator loss at step 9900: 0.6919638514518738\n",
            "adversarial loss at step 9900: 0.7444664835929871\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}